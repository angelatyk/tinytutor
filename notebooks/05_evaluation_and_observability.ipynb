{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgHZ6NIKRG9DLvg5YeyrKd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Observability"
      ],
      "metadata": {
        "id": "v1Lde8UYC29k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "##  Final System Prompt for `05_evaluation_and_observability.ipynb`\n",
        "\n",
        "###  Notebook Title:\n",
        "**TinyTutor Capstone Notebook 05: Evaluation and Observability**\n",
        "\n",
        "###  Objective:\n",
        "Implement robust **evaluation** and **observability** mechanisms for the TinyTutor multi-agent system using ADK. This notebook must demonstrate how the system can:\n",
        "- Critique its own outputs using rubric-based scoring\n",
        "- Enforce safety guardrails\n",
        "- Expose its full internal decision-making trajectory\n",
        "This establishes the foundation for **AgentOps discipline** and ensures the system is **evaluatable by design**.\n",
        "\n",
        "---\n",
        "\n",
        "###  System Prompt:\n",
        "> Generate runnable Python code for `05_evaluation_and_observability.ipynb` that extends the TinyTutor multi-agent pipeline with evaluation and observability features. Implement the following:\n",
        ">\n",
        "> 1. **Pipeline Reuse**:\n",
        ">     - Re-import or redefine the `TinyTutorCoordinator` and sub-agents/tools from Notebook 04.\n",
        ">\n",
        "> 2. **Observability Setup**:\n",
        ">     - Configure the ADK `Runner` with `LoggingPlugin` and set `log_level=DEBUG`.\n",
        ">     - Ensure full trace visibility: agent thoughts, tool calls, arguments, and outputs.\n",
        ">\n",
        "> 3. **SafetyCheckerAgent**:\n",
        ">     - Define an `LlmAgent` named `SafetyCheckerAgent`.\n",
        ">     - Instruction: Review `{final_script}` for age-appropriateness, harmful content, and safety policy adherence.\n",
        ">     - Simulate using Gemini 1.5 Pro.\n",
        ">     - Output: Structured JSON with `status: pass/fail` and `justification`.\n",
        ">\n",
        "> 4. **EvaluatorAgent (LLM-as-a-Judge)**:\n",
        ">     - Define an `LlmAgent` named `EvaluatorAgent`.\n",
        ">     - Instruction: Score `{final_script}` using a rubric (e.g., Simplicity, Coherence, ELI5 adherence; scale 1–5).\n",
        ">     - Output: Structured JSON with scores and summary.\n",
        ">\n",
        "> 5. **LoopAgent Pattern (Optional)**:\n",
        ">     - Wrap the `ScriptwritingAgent` in a `LoopAgent` that repeats until the EvaluatorAgent returns an “Approved” score or passes a threshold.\n",
        ">\n",
        "> 6. **Execution**:\n",
        ">     - Run the full pipeline with a complex topic (e.g., “The mechanism of photosynthesis”).\n",
        ">     - Display:\n",
        ">         - Full execution trace\n",
        ">         - Safety check result\n",
        ">         - Evaluation scores\n",
        ">         - Final approved script\n",
        ">\n",
        "> 7. **Best Practices**:\n",
        ">     - Use structured outputs and type hints\n",
        ">     - Redact PII before logging or storing\n",
        ">     - Include inline comments and Markdown to explain architecture, evaluation logic, and Capstone alignment\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Checklist for `05_evaluation_and_observability.ipynb`\n",
        "\n",
        "| **Category**         | **Requirement**                                                                                                                                       | **Source/Justification**                                                                 |\n",
        "|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
        "| **Core Concept**      | AgentOps: Evaluation and Observability as architectural pillars                                                                                      | Capstone delivery requirement                                                             |\n",
        "| **Goal**              | Integrate safety checks and quality scoring; expose full agent trajectory                                                                            | Ensures transparency, reliability, and trustworthiness                                    |\n",
        "| **Dependencies**      | Requires full pipeline from Notebook 04                                                                                                              | Builds on multi-agent orchestration and memory logic                                      |\n",
        "| **Required Tools**    | - `LoggingPlugin` with `log_level=DEBUG` <br> - `SafetyCheckerAgent` <br> - `EvaluatorAgent` <br> - Optional: `LoopAgent`                            | Enables traceability and iterative refinement                                             |\n",
        "| **Agent Design**      | - SafetyCheckerAgent: non-negotiable guardrail <br> - EvaluatorAgent: rubric-based quality judge                                                     | Mirrors real-world QA and compliance workflows                                            |\n",
        "| **Evaluation Logic**  | - Safety: pass/fail + justification <br> - Quality: rubric scores (1–5)                                                                              | Validates pedagogical clarity and child-appropriateness                                   |\n",
        "| **Execution**         | - Run full pipeline with complex topic <br> - Show trace, scores, and final output                                                                  | Demonstrates system maturity and readiness                                                |\n",
        "| **Architecture**      | - Evaluatable by design <br> - LoopAgent for iterative refinement                                                                                    | Aligns with AgentOps and Capstone rubric                                                  |\n",
        "| **Good Practices**    | - Structured logs and metrics <br> - Redact sensitive data <br> - Use clear scoring schema                                                           | Ensures compliance, clarity, and reproducibility                                          |\n",
        "| **Documentation**     | - Inline comments <br> - Markdown explanations                                                                                                       | Supports Capstone reviewers and future collaborators                                      |\n",
        "\n",
        "---\n",
        "\n",
        "###  What We’ll Have When This Code Is Done\n",
        "\n",
        "-  A fully observable, evaluatable multi-agent pipeline\n",
        "-  Two specialized critique agents: one for safety, one for quality\n",
        "-  A traceable execution log showing agent thoughts, tool calls, and outputs\n",
        "-  A rubric-based scoring system for pedagogical quality\n",
        "-  Optional loop logic for iterative refinement\n",
        "-  Clear documentation and inline logic to support Capstone delivery and debugging\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-_hUYzP0g0NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code here"
      ],
      "metadata": {
        "id": "2xacYa3-JL2b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}