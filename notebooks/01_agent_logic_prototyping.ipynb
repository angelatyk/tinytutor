{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97c49ac0",
      "metadata": {
        "id": "97c49ac0"
      },
      "source": [
        "# Agent Logic Prototyping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Final System Prompt for `01_agent_logic_prototyping.ipynb`\n",
        "\n",
        "###  Notebook Title:\n",
        "**TinyTutor Capstone Notebook 01: Agent Logic Prototyping (Text & Reasoning)**\n",
        "\n",
        "###  Objective:\n",
        "Define and prototype the **core reasoning agents** for TinyTutor using **Google ADK** and **Gemini 2.5 Flash-Lite**. This notebook establishes the foundational **ELI5 (Explain Like I’m 5)** logic and deterministic **Sequential Workflow** that powers the system’s text-based pedagogy. It also introduces **multimodal input handling** (text/audio) and prepares the agent for future tool orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "###  System Prompt:\n",
        "> Generate runnable Python code for `01_agent_logic_prototyping.ipynb` that defines the foundational reasoning agents for TinyTutor. Use the Google ADK framework and Gemini 2.5 Flash-Lite model. Implement the following:\n",
        ">\n",
        "> 1. **PedagogyAgent** (`LlmAgent`): A kindergarten-teacher persona that simplifies complex topics into short, metaphor-rich explanations for 5-year-olds. Store its output in session state as `eli5_explanation`.\n",
        ">\n",
        "> 2. **ScriptwritingAgent** (`LlmAgent`): Transforms the ELI5 explanation into a structured, child-friendly story with characters and pacing. It must consume `{eli5_explanation}` via session state and output `final_script`.\n",
        ">\n",
        "> 3. **SequentialAgent** (`TextPipeline`): Orchestrates the deterministic flow: PedagogyAgent → ScriptwritingAgent.\n",
        ">\n",
        "> 4. **Audio Input Tool**: Define a simple `audio_to_text(audio_file_path: str) -> str` FunctionTool. Instruct the PedagogyAgent to invoke this tool if the input is ambiguous or marked as audio.\n",
        ">\n",
        "> 5. **Execution**: Use `InMemoryRunner` to demonstrate a full run with the query: “Explain how Black Holes work like I am 5.” Log all intermediate outputs.\n",
        ">\n",
        "> Bonus: Add inline comments and Markdown to explain the agent roles, architecture, and how this notebook fulfills Level 0–1 Capstone capabilities.\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Checklist for `01_agent_logic_prototyping.ipynb`\n",
        "\n",
        "| **Category**         | **Requirement**                                                                                                                                       | **Source/Justification**                                                                 |\n",
        "|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
        "| **Goal**              | Implement the core reasoning flow: **Simplification → Story Script Generation** using a deterministic sequential agent pipeline                      | Capstone Level 1 architecture                                                             |\n",
        "| **Dependencies**      | None (Foundational logic)                                                                                                                             | This is the base layer for all downstream agents                                          |\n",
        "| **Required Tools**    | - Gemini 2.5 Flash-Lite (for fast, cost-effective reasoning) <br> - ADK `LlmAgent`, `SequentialAgent`, `InMemoryRunner` <br> - Custom `audio_to_text` | Ensures reasoning and tool invocation are testable                                        |\n",
        "| **Agent Design**      | - `PedagogyAgent`: ELI5 simplifier <br> - `ScriptwritingAgent`: Story generator <br> - `TextPipeline`: Sequential orchestrator                        | Mirrors real-world educational scaffolding                                                |\n",
        "| **Tool Integration**  | Define `audio_to_text()` and instruct agent to use it if input is audio or ambiguous                                                                 | Prepares for multimodal input in Notebook 02                                              |\n",
        "| **Architecture**      | Use `SequentialAgent` to enforce deterministic flow                                                                                                  | Guarantees pedagogical order: simplify → narrate                                          |\n",
        "| **State Management**  | Use `output_key` to pass `eli5_explanation` to `ScriptwritingAgent`                                                                                  | Demonstrates context engineering and modularity                                           |\n",
        "| **Execution**         | Run a full example with the topic: “Explain how Black Holes work like I am 5”                                                                        | Validates agent logic and state passing                                                   |\n",
        "| **Good Practices**    | - Clear system instructions <br> - Inline comments <br> - Markdown explanations                                                                      | Improves readability and Capstone documentation                                           |\n",
        "| **Output Expectations** | - Printed `eli5_explanation` <br> - Printed `final_script` <br> - Optional: log tool usage or fallback logic                                       | Confirms agent reasoning and tool invocation                                              |\n",
        "\n",
        "---\n",
        "\n",
        "###  What You’ll Have When This Code Is Done\n",
        "\n",
        "-  A fully functional **text reasoning pipeline** for TinyTutor\n",
        "-  Two modular agents: one for simplification, one for storytelling\n",
        "-  A deterministic execution flow using `SequentialAgent`\n",
        "-  A working audio input handler (`audio_to_text`) for future multimodal expansion\n",
        "-  A debug run that proves the system can simplify and narrate a complex topic for a 5-year-old\n",
        "-  Clear documentation and inline logic to support Capstone reviewers and future collaborators\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "wAXg-kpb6Vh9"
      },
      "id": "wAXg-kpb6Vh9"
    },
    {
      "cell_type": "code",
      "source": [
        "# code here"
      ],
      "metadata": {
        "id": "WCuK-3hN6U2Y"
      },
      "id": "WCuK-3hN6U2Y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}