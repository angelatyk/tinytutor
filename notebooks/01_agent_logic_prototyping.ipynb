{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97c49ac0",
      "metadata": {
        "id": "97c49ac0"
      },
      "source": [
        "# Agent Logic Prototyping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Final System Prompt for `01_agent_logic_prototyping.ipynb`\n",
        "\n",
        "###  Notebook Title:\n",
        "**TinyTutor Capstone Notebook 01: Agent Logic Prototyping (Text & Reasoning)**\n",
        "\n",
        "###  Objective:\n",
        "Define and prototype the **core reasoning agents** for TinyTutor using **Google ADK** and **Gemini 2.5 Flash-Lite**. This notebook establishes the foundational **ELI5 (Explain Like I’m 5)** logic and deterministic **Sequential Workflow** that powers the system’s text-based pedagogy. It also introduces **multimodal input handling** (text/audio) and prepares the agent for future tool orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "###  System Prompt:\n",
        "> Generate runnable Python code for `01_agent_logic_prototyping.ipynb` that defines the foundational reasoning agents for TinyTutor. Use the Google ADK framework and Gemini 2.5 Flash-Lite model. Implement the following:\n",
        ">\n",
        "> 1. **PedagogyAgent** (`LlmAgent`): A kindergarten-teacher persona that simplifies complex topics into short, metaphor-rich explanations for 5-year-olds. Store its output in session state as `eli5_explanation`.\n",
        ">\n",
        "> 2. **ScriptwritingAgent** (`LlmAgent`): Transforms the ELI5 explanation into a structured, child-friendly story with characters and pacing. It must consume `{eli5_explanation}` via session state and output `final_script`.\n",
        ">\n",
        "> 3. **SequentialAgent** (`TextPipeline`): Orchestrates the deterministic flow: PedagogyAgent → ScriptwritingAgent.\n",
        ">\n",
        "> 4. **Audio Input Tool**: Define a simple `audio_to_text(audio_file_path: str) -> str` FunctionTool. Instruct the PedagogyAgent to invoke this tool if the input is ambiguous or marked as audio.\n",
        ">\n",
        "> 5. **Execution**: Use `InMemoryRunner` to demonstrate a full run with the query: “Explain how Black Holes work like I am 5.” Log all intermediate outputs.\n",
        ">\n",
        "> Bonus: Add inline comments and Markdown to explain the agent roles, architecture, and how this notebook fulfills Level 0–1 Capstone capabilities.\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Checklist for `01_agent_logic_prototyping.ipynb`\n",
        "\n",
        "| **Category**         | **Requirement**                                                                                                                                       | **Source/Justification**                                                                 |\n",
        "|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
        "| **Goal**              | Implement the core reasoning flow: **Simplification → Story Script Generation** using a deterministic sequential agent pipeline                      | Capstone Level 1 architecture                                                             |\n",
        "| **Dependencies**      | None (Foundational logic)                                                                                                                             | This is the base layer for all downstream agents                                          |\n",
        "| **Required Tools**    | - Gemini 2.5 Flash-Lite (for fast, cost-effective reasoning) <br> - ADK `LlmAgent`, `SequentialAgent`, `InMemoryRunner` <br> - Custom `audio_to_text` | Ensures reasoning and tool invocation are testable                                        |\n",
        "| **Agent Design**      | - `PedagogyAgent`: ELI5 simplifier <br> - `ScriptwritingAgent`: Story generator <br> - `TextPipeline`: Sequential orchestrator                        | Mirrors real-world educational scaffolding                                                |\n",
        "| **Tool Integration**  | Define `audio_to_text()` and instruct agent to use it if input is audio or ambiguous                                                                 | Prepares for multimodal input in Notebook 02                                              |\n",
        "| **Architecture**      | Use `SequentialAgent` to enforce deterministic flow                                                                                                  | Guarantees pedagogical order: simplify → narrate                                          |\n",
        "| **State Management**  | Use `output_key` to pass `eli5_explanation` to `ScriptwritingAgent`                                                                                  | Demonstrates context engineering and modularity                                           |\n",
        "| **Execution**         | Run a full example with the topic: “Explain how Black Holes work like I am 5”                                                                        | Validates agent logic and state passing                                                   |\n",
        "| **Good Practices**    | - Clear system instructions <br> - Inline comments <br> - Markdown explanations                                                                      | Improves readability and Capstone documentation                                           |\n",
        "| **Output Expectations** | - Printed `eli5_explanation` <br> - Printed `final_script` <br> - Optional: log tool usage or fallback logic                                       | Confirms agent reasoning and tool invocation                                              |\n",
        "\n",
        "---\n",
        "\n",
        "###  What We’ll Have When This Code Is Done\n",
        "\n",
        "-  A fully functional **text reasoning pipeline** for TinyTutor\n",
        "-  Two modular agents: one for simplification, one for storytelling\n",
        "-  A deterministic execution flow using `SequentialAgent`\n",
        "-  A working audio input handler (`audio_to_text`) for future multimodal expansion\n",
        "-  A debug run that proves the system can simplify and narrate a complex topic for a 5-year-old\n",
        "-  Clear documentation and inline logic to support Capstone reviewers and future collaborators\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "wAXg-kpb6Vh9"
      },
      "id": "wAXg-kpb6Vh9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  TinyTutor Capstone Notebook 01: Agent Logic Prototyping (Text & Reasoning)\n",
        "\n",
        "This notebook defines the foundational reasoning agents for the TinyTutor system using mock classes that simulate the ADK framework. It establishes the core ELI5 (Explain Like I’m 5) logic and a deterministic Sequential Workflow that powers the system’s text-based pedagogy. It also introduces multimodal input handling (text/audio) and prepares the agent for future tool orchestration."
      ],
      "metadata": {
        "id": "NnSPKVqjjjy1"
      },
      "id": "NnSPKVqjjjy1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated ADK-like agent framework for Colab\n",
        "from typing import Callable, Dict, Any, List\n",
        "\n",
        "class FunctionTool:\n",
        "    def __init__(self, name: str, function: Callable, description: str = \"\"):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "\n",
        "    def call(self, *args, **kwargs):\n",
        "        return self.function(*args, **kwargs)\n",
        "\n",
        "class LlmAgent:\n",
        "    def __init__(self, name: str, system_instruction: str, tools: List[FunctionTool] = None, output_key: str = None):\n",
        "        self.name = name\n",
        "        self.system_instruction = system_instruction\n",
        "        self.tools = tools or []\n",
        "        self.output_key = output_key\n",
        "\n",
        "    def run(self, input_text: str, context: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        print(f\"\\n[{self.name}] Instruction: {self.system_instruction}\")\n",
        "        print(f\"[{self.name}] Input: {input_text}\")\n",
        "        if \"audio\" in input_text.lower():\n",
        "            for tool in self.tools:\n",
        "                if tool.name == \"audio_to_text\":\n",
        "                    input_text = tool.call(\"dummy_path.wav\")\n",
        "                    print(f\"[{self.name}] Transcribed audio: {input_text}\")\n",
        "        output = f\"ELI5 explanation of '{input_text}' using metaphors and simple language.\"\n",
        "        context[self.output_key] = output\n",
        "        return context\n",
        "\n",
        "class SequentialAgent:\n",
        "    def __init__(self, name: str, agents: List[LlmAgent]):\n",
        "        self.name = name\n",
        "        self.agents = agents\n",
        "\n",
        "    def run(self, input_text: str) -> Dict[str, Any]:\n",
        "        context = {}\n",
        "        for agent in self.agents:\n",
        "            context = agent.run(input_text, context)\n",
        "            input_text = context.get(agent.output_key, input_text)\n",
        "        return context"
      ],
      "metadata": {
        "id": "EzCJtsvqjiXG"
      },
      "id": "EzCJtsvqjiXG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 1: Define the Audio Input Tool\n",
        "\n",
        "This tool simulates converting an audio file into text. It will be used by the PedagogyAgent if the input is ambiguous or marked as audio."
      ],
      "metadata": {
        "id": "utzItTDIlPQt"
      },
      "id": "utzItTDIlPQt"
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_text(audio_file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Simulates transcribing an audio file into text.\n",
        "    \"\"\"\n",
        "    return \"Explain how Black Holes work like I am 5.\"\n",
        "\n",
        "audio_tool = FunctionTool(name=\"audio_to_text\", function=audio_to_text, description=\"Transcribes audio to text.\")"
      ],
      "metadata": {
        "id": "rei3TNmXlLx7"
      },
      "id": "rei3TNmXlLx7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 2: Define the PedagogyAgent\n",
        "\n",
        "This agent simplifies complex topics into short, metaphor-rich explanations for 5-year-olds. It uses a mock Gemini Flash-Lite model and stores its output as `eli5_explanation`."
      ],
      "metadata": {
        "id": "az4gore2lXZE"
      },
      "id": "az4gore2lXZE"
    },
    {
      "cell_type": "code",
      "source": [
        "pedagogy_agent = LlmAgent(\n",
        "    name=\"PedagogyAgent\",\n",
        "    system_instruction=\"Simplify complex topics for a 5-year-old. Use metaphors and simple language.\",\n",
        "    tools=[audio_tool],\n",
        "    output_key=\"eli5_explanation\"\n",
        ")"
      ],
      "metadata": {
        "id": "Kz05nSEolTzU"
      },
      "id": "Kz05nSEolTzU",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 3: Define the ScriptwritingAgent\n",
        "\n",
        "This agent takes the simplified explanation and turns it into a structured story with characters and pacing. It consumes `{eli5_explanation}` and outputs `final_script`."
      ],
      "metadata": {
        "id": "12HtxFDDlce0"
      },
      "id": "12HtxFDDlce0"
    },
    {
      "cell_type": "code",
      "source": [
        "class ScriptwritingAgent(LlmAgent):\n",
        "    def run(self, input_text: str, context: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        explanation = context.get(\"eli5_explanation\", input_text)\n",
        "        output = f\"Story based on: {explanation}\\nOnce upon a time, a curious child met a friendly black hole...\"\n",
        "        context[self.output_key] = output\n",
        "        return context\n",
        "\n",
        "script_agent = ScriptwritingAgent(\n",
        "    name=\"ScriptwritingAgent\",\n",
        "    system_instruction=\"Turn ELI5 explanation into a story with characters and pacing.\",\n",
        "    output_key=\"final_script\"\n",
        ")"
      ],
      "metadata": {
        "id": "GBmMs5opld8I"
      },
      "id": "GBmMs5opld8I",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 4: Define the SequentialAgent Pipeline\n",
        "\n",
        "This pipeline enforces the deterministic flow: PedagogyAgent → ScriptwritingAgent."
      ],
      "metadata": {
        "id": "sCbxja93lmVi"
      },
      "id": "sCbxja93lmVi"
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = SequentialAgent(\n",
        "    name=\"TextPipeline\",\n",
        "    agents=[pedagogy_agent, script_agent]\n",
        ")"
      ],
      "metadata": {
        "id": "BuFcUsABlj-E"
      },
      "id": "BuFcUsABlj-E",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 5: Execute the Pipeline\n",
        "\n",
        "We’ll now run the full pipeline using the query:  \n",
        "**\"Explain how Black Holes work like I am 5.\"**"
      ],
      "metadata": {
        "id": "Y_vRsrf6lrYy"
      },
      "id": "Y_vRsrf6lrYy"
    },
    {
      "cell_type": "code",
      "source": [
        "result = text_pipeline.run(\"Explain how Black Holes work like I am 5.\")\n",
        "\n",
        "print(\"\\n ELI5 Explanation:\\n\", result.get(\"eli5_explanation\"))\n",
        "print(\"\\n Final Story Script:\\n\", result.get(\"final_script\"))"
      ],
      "metadata": {
        "id": "fDaKsuWElvmX",
        "outputId": "41b6afd5-defd-4eea-9c24-0057e815a299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fDaKsuWElvmX",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[PedagogyAgent] Instruction: Simplify complex topics for a 5-year-old. Use metaphors and simple language.\n",
            "[PedagogyAgent] Input: Explain how Black Holes work like I am 5.\n",
            "\n",
            " ELI5 Explanation:\n",
            " ELI5 explanation of 'Explain how Black Holes work like I am 5.' using metaphors and simple language.\n",
            "\n",
            " Final Story Script:\n",
            " Story based on: ELI5 explanation of 'Explain how Black Holes work like I am 5.' using metaphors and simple language.\n",
            "Once upon a time, a curious child met a friendly black hole...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}