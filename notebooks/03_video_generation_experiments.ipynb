{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12480d3a",
      "metadata": {
        "id": "12480d3a"
      },
      "source": [
        "# Video Generation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "##  Final System Prompt for `03_video_generation_experiments.ipynb`\n",
        "\n",
        "###  Notebook Title:\n",
        "**TinyTutor Capstone Notebook 03: Video Generation Experiments**\n",
        "\n",
        "###  Objective:\n",
        "Define and test the **visual media generation tools** for TinyTutor using ADK `FunctionTool` wrappers. These tools simulate the transformation of a child-friendly story script into engaging visual assets—images, videos, and coherent scenes—using structured inputs and mocked outputs. The notebook must demonstrate tool modularity, agent compatibility, and adherence to ADK and MCP best practices.\n",
        "\n",
        "---\n",
        "\n",
        "###  System Prompt:\n",
        "> Generate runnable Python code for `03_video_generation_experiments.ipynb` that defines and tests TinyTutor’s visual media tools. Implement the following:\n",
        ">\n",
        "> 1. **Tool 1: `generate_hyper_image_imagen(prompt: str, style: str) -> dict`**\n",
        ">     - Simulates image generation using Imagen 3 or Nano Banana.\n",
        ">     - Returns a structured dictionary with an image URI (e.g., `{'status': 'success', 'image_uri': 'data/images/scene1.png'}`).\n",
        ">     - Include a clear docstring describing its purpose and required parameters.\n",
        ">\n",
        "> 2. **Tool 2: `generate_smooth_video_lumiere(scene_description: str, duration_sec: int) -> dict`**\n",
        ">     - Simulates video generation using Lumiere or Veo 3.\n",
        ">     - Returns a structured dictionary with a video URI.\n",
        ">     - Include a docstring emphasizing child-friendly output and duration constraints.\n",
        ">\n",
        "> 3. **Tool 3: `combine_scenes_whisk(artifact_id_list: List[str]) -> dict`**\n",
        ">     - Simulates scene composition using Whisk.\n",
        ">     - Accepts a list of image/video URIs and returns a single cohesive scene URI.\n",
        ">     - Include a docstring describing its role in merging visual assets.\n",
        ">\n",
        "> 4. **Tool Wrapping**:\n",
        ">     - Wrap all three functions as ADK `FunctionTool` objects.\n",
        ">     - Ensure type hints, structured outputs, and discoverability by agents.\n",
        ">\n",
        "> 5. **Test Agent (`VisualTestAgent`)**:\n",
        ">     - Create an `LlmAgent` equipped with all three tools.\n",
        ">     - Run a mock sequence:\n",
        ">         - Generate an image from a scene prompt\n",
        ">         - Generate a video from a description\n",
        ">         - Merge them into a final scene\n",
        ">     - Confirm successful tool invocation and output parsing.\n",
        ">\n",
        "> 6. **Best Practices**:\n",
        ">     - Avoid raw media data in outputs\n",
        ">     - Use concise artifact URIs\n",
        ">     - Log tool parameters and agent decisions\n",
        ">     - Include inline comments and Markdown to explain tool design and Capstone relevance\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Checklist for `03_video_generation_experiments.ipynb`\n",
        "\n",
        "| **Category**         | **Requirement**                                                                                                                                       | **Source/Justification**                                                                 |\n",
        "|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
        "| **Core Concept**      | Extending **Multimodal Action** capabilities (“Hands”)                                                                                               | Capstone Level 2–3 architecture                                                           |\n",
        "| **Goal**              | Define and wrap custom tools for image, video, and scene composition                                                                                 | Enables visual storytelling for TinyTutor                                                 |\n",
        "| **Dependencies**      | Requires scene descriptions and style inputs from Notebook 01 (`final_script`)                                                                      | Demonstrates tool chaining and multimodal readiness                                       |\n",
        "| **Required Tools**    | - `generate_hyper_image_imagen(prompt, style)` <br> - `generate_smooth_video_lumiere(scene_description, duration_sec)` <br> - `combine_scenes_whisk(artifact_id_list)` | Simulates Imagen, Lumiere, and Whisk workflows                                           |\n",
        "| **Tool Design**       | - Clear docstrings <br> - Type hints <br> - Structured outputs (URIs only)                                                                           | Aligns with ADK and MCP best practices                                                    |\n",
        "| **Output Format**     | - Each tool returns: `{'status': 'success', 'artifact_uri': '...'}`                                                                                  | Prevents context bloat and ensures clarity                                                |\n",
        "| **Agent Execution**   | - `VisualTestAgent` must call all three tools <br> - Confirm tool invocation and output parsing                                                      | Validates tool integration and agent orchestration                                        |\n",
        "| **Architecture**      | - FunctionTool wrappers <br> - LlmAgent with tool access                                                                                             | Mirrors production-ready ADK design                                                       |\n",
        "| **Good Practices**    | - Avoid raw media data <br> - Use concise artifact references <br> - Log tool usage                                                                 | Ensures scalability and traceability                                                      |\n",
        "| **Documentation**     | - Inline comments <br> - Markdown explanations                                                                                                       | Supports Capstone reviewers and future collaborators                                      |\n",
        "\n",
        "---\n",
        "\n",
        "###  What We’ll Have When This Code Is Done\n",
        "\n",
        "-  Three production-ready visual media tools: image generation, video synthesis, and scene composition\n",
        "-  ADK-compliant FunctionTool wrappers with clear docstrings and structured outputs\n",
        "-  A test agent that demonstrates tool invocation and output parsing\n",
        "-  Simulated visual artifacts for downstream use\n",
        "-  Clear documentation and inline logic to support Capstone delivery and debugging\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ZCvABfvKeEP2"
      },
      "id": "ZCvABfvKeEP2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  TinyTutor Capstone Notebook 03: Video Generation Experiments\n",
        "\n",
        "This notebook defines and tests the visual media tools for TinyTutor using mock classes that simulate ADK `FunctionTool` behavior. It introduces:\n",
        "- An image generation tool (simulating Imagen 3 or Nano Banana)\n",
        "- A video synthesis tool (simulating Lumiere or Veo 3)\n",
        "- A scene composition tool (simulating Whisk)\n",
        "These tools are modular, agent-compatible, and return structured artifact references for downstream use."
      ],
      "metadata": {
        "id": "qRdZlDMmo689"
      },
      "id": "qRdZlDMmo689"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Dict, Any, List\n",
        "\n",
        "class FunctionTool:\n",
        "    def __init__(self, name: str, function: Callable, description: str = \"\"):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "\n",
        "    def call(self, *args, **kwargs):\n",
        "        return self.function(*args, **kwargs)\n",
        "\n",
        "class LlmAgent:\n",
        "    def __init__(self, name: str, system_instruction: str, tools: List[FunctionTool] = None):\n",
        "        self.name = name\n",
        "        self.system_instruction = system_instruction\n",
        "        self.tools = tools or []\n",
        "\n",
        "    def run(self, input_text: str) -> Dict[str, Any]:\n",
        "        print(f\"\\n[{self.name}] Instruction: {self.system_instruction}\")\n",
        "        print(f\"[{self.name}] Input: {input_text}\")\n",
        "        results = {}\n",
        "        for tool in self.tools:\n",
        "            if tool.name == \"generate_hyper_image_imagen\":\n",
        "                results[\"image\"] = tool.call(prompt=input_text, style=\"cartoon\")\n",
        "            elif tool.name == \"generate_smooth_video_lumiere\":\n",
        "                results[\"video\"] = tool.call(scene_description=input_text, duration_sec=10)\n",
        "            elif tool.name == \"combine_scenes_whisk\":\n",
        "                results[\"scene\"] = tool.call(artifact_id_list=[\"img_001\", \"vid_001\"])\n",
        "        return results"
      ],
      "metadata": {
        "id": "1YvNhGIwIh0J"
      },
      "id": "1YvNhGIwIh0J",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 1: Define the Image Generation Tool\n",
        "\n",
        "This tool simulates generating a child-friendly image from a scene prompt and style."
      ],
      "metadata": {
        "id": "AyVRy7ILpHWY"
      },
      "id": "AyVRy7ILpHWY"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_hyper_image_imagen(prompt: str, style: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Simulates generating an image from a prompt and style.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Scene description.\n",
        "        style (str): Visual style (e.g., 'cartoon').\n",
        "\n",
        "    Returns:\n",
        "        dict: Simulated image URI.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"image_uri\": \"data/images/scene1.png\",\n",
        "        \"style\": style\n",
        "    }\n",
        "\n",
        "image_tool = FunctionTool(\n",
        "    name=\"generate_hyper_image_imagen\",\n",
        "    function=generate_hyper_image_imagen,\n",
        "    description=\"Generates a child-friendly image from a scene prompt.\"\n",
        ")"
      ],
      "metadata": {
        "id": "poIvw4HDpGAd"
      },
      "id": "poIvw4HDpGAd",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 2: Define the Video Generation Tool\n",
        "\n",
        "This tool simulates generating a short video from a scene description and duration."
      ],
      "metadata": {
        "id": "MO1Ik7OlpLtk"
      },
      "id": "MO1Ik7OlpLtk"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_smooth_video_lumiere(scene_description: str, duration_sec: int) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Simulates generating a video from a scene description.\n",
        "\n",
        "    Args:\n",
        "        scene_description (str): Description of the scene.\n",
        "        duration_sec (int): Duration of the video in seconds.\n",
        "\n",
        "    Returns:\n",
        "        dict: Simulated video URI.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"video_uri\": \"data/videos/scene1.mp4\",\n",
        "        \"duration\": duration_sec\n",
        "    }\n",
        "\n",
        "video_tool = FunctionTool(\n",
        "    name=\"generate_smooth_video_lumiere\",\n",
        "    function=generate_smooth_video_lumiere,\n",
        "    description=\"Generates a short video from a scene description.\"\n",
        ")"
      ],
      "metadata": {
        "id": "_OUfhL1UpOtv"
      },
      "id": "_OUfhL1UpOtv",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 3: Define the Scene Composition Tool\n",
        "\n",
        "This tool simulates merging multiple visual artifacts into a single cohesive scene."
      ],
      "metadata": {
        "id": "Z6ahOEeLpQwR"
      },
      "id": "Z6ahOEeLpQwR"
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_scenes_whisk(artifact_id_list: List[str]) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Simulates combining multiple visual artifacts into a single scene.\n",
        "\n",
        "    Args:\n",
        "        artifact_id_list (List[str]): List of image/video IDs.\n",
        "\n",
        "    Returns:\n",
        "        dict: Simulated scene URI.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"scene_uri\": \"data/scenes/final_scene.mp4\",\n",
        "        \"combined_ids\": artifact_id_list\n",
        "    }\n",
        "\n",
        "scene_tool = FunctionTool(\n",
        "    name=\"combine_scenes_whisk\",\n",
        "    function=combine_scenes_whisk,\n",
        "    description=\"Combines visual artifacts into a single cohesive scene.\"\n",
        ")"
      ],
      "metadata": {
        "id": "pAaL66eEpSjo"
      },
      "id": "pAaL66eEpSjo",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 4: Define the VisualTestAgent\n",
        "\n",
        "This agent is equipped with all three visual tools and can generate images, videos, and composed scenes."
      ],
      "metadata": {
        "id": "jvYrAWKopU5_"
      },
      "id": "jvYrAWKopU5_"
    },
    {
      "cell_type": "code",
      "source": [
        "visual_agent = LlmAgent(\n",
        "    name=\"VisualTestAgent\",\n",
        "    system_instruction=\"Use tools to generate visuals from a scene prompt.\",\n",
        "    tools=[image_tool, video_tool, scene_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "sCnIW5WMpWNS"
      },
      "id": "sCnIW5WMpWNS",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 5: Run Tool Tests\n",
        "\n",
        "We’ll now simulate:\n",
        "- Generating an image from a scene prompt\n",
        "- Generating a video from the same prompt\n",
        "- Merging them into a final scene"
      ],
      "metadata": {
        "id": "paJH10B5pYeY"
      },
      "id": "paJH10B5pYeY"
    },
    {
      "cell_type": "code",
      "source": [
        "scene_prompt = \"A friendly space pirate waving hello on a colorful planet.\"\n",
        "\n",
        "results = visual_agent.run(scene_prompt)\n",
        "\n",
        "print(\"\\n Image Output:\\n\", results.get(\"image\"))\n",
        "print(\"\\n Video Output:\\n\", results.get(\"video\"))\n",
        "print(\"\\n Scene Composition Output:\\n\", results.get(\"scene\"))"
      ],
      "metadata": {
        "id": "GZNicgk1paFP",
        "outputId": "6d16c0eb-217d-4a00-b5bc-176233eedb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GZNicgk1paFP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[VisualTestAgent] Instruction: Use tools to generate visuals from a scene prompt.\n",
            "[VisualTestAgent] Input: A friendly space pirate waving hello on a colorful planet.\n",
            "\n",
            " Image Output:\n",
            " {'status': 'success', 'image_uri': 'data/images/scene1.png', 'style': 'cartoon'}\n",
            "\n",
            " Video Output:\n",
            " {'status': 'success', 'video_uri': 'data/videos/scene1.mp4', 'duration': 10}\n",
            "\n",
            " Scene Composition Output:\n",
            " {'status': 'success', 'scene_uri': 'data/scenes/final_scene.mp4', 'combined_ids': ['img_001', 'vid_001']}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}